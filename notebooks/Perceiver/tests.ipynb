{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import functools\n",
    "import os\n",
    "import pickle\n",
    "import ssl\n",
    "import re\n",
    "import tempfile\n",
    "\n",
    "from urllib import request\n",
    "\n",
    "import cv2\n",
    "import imageio\n",
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_gif(images):\n",
    "    converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
    "    imageio.mimsave('./animation.gif', converted_images, fps=25)\n",
    "    with open('./animation.gif', 'rb') as f:\n",
    "        gif_64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "    return HTML('<img src=\"data:image/gif;base64,%s\"/>' % gif_64)\n",
    "\n",
    "def play_audio(data, sample_rate=48000):\n",
    "    scipy.io.wavfile.write('tmp_audio.wav', sample_rate, data)\n",
    "\n",
    "    with open('./tmp_audio.wav', 'rb') as f:\n",
    "        audio_64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "    return HTML('<audio controls src=\"data:audio/wav;base64,%s\"/>' % audio_64)\n",
    "\n",
    "def table(elements):\n",
    "    row = ['<td>%s</td>' % el.data for el in elements]\n",
    "    return HTML('<table><tr>%s</tr></table>' % ''.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "hf = h5py.File(\"y_train.h5\", \"r\")\n",
    "data = hf.get(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5, -1.2,  1.8, ...,  0.6, -0.4,  2. ])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# pickle.load(\"mosi_data.pkl\")\n",
    "with open(\"mosi_data.pkl\", 'rb') as pickle_file:\n",
    "    content = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vision', 'labels', 'text', 'audio', 'id'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[\"train\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1284, 50, 20)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[\"train\"][\"vision\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(content[\"train\"][\"vision\"][570,: ,:])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1284, 1, 1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[\"train\"][\"labels\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.4 ],\n",
       "       [-0.8 ],\n",
       "       [-1.  ],\n",
       "       [-1.75],\n",
       "       [ 0.  ],\n",
       "       [ 0.  ],\n",
       "       [ 0.8 ],\n",
       "       [ 0.  ],\n",
       "       [ 0.2 ],\n",
       "       [-1.2 ],\n",
       "       [-0.5 ],\n",
       "       [ 2.2 ],\n",
       "       [ 1.8 ]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = h5py.File(\"CMU_MOSI_Opinion_Labels.csd\", \"r\")\n",
    "np.array(h.get(\"Opinion Segment Labels\").get(\"data\").get(\"03bSnISJMiM\").get(\"features\"))\n",
    "# np.array(h.get(\"Opinion Segment Labels\").get(\"metadata\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 51.904533,  55.94535 ],\n",
       "       [ 56.045124,  66.78072 ],\n",
       "       [ 66.78072 ,  68.73628 ],\n",
       "       [ 68.73628 ,  70.542175],\n",
       "       [ 70.542175,  71.69955 ],\n",
       "       [ 71.69955 ,  72.85692 ],\n",
       "       [ 72.85692 ,  77.79569 ],\n",
       "       [ 77.79569 ,  89.52902 ],\n",
       "       [ 89.52902 ,  92.23288 ],\n",
       "       [ 92.23288 ,  94.80703 ],\n",
       "       [ 94.80703 ,  96.57301 ],\n",
       "       [ 96.57301 ,  99.01746 ],\n",
       "       [168.65918 , 170.24557 ]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a full array from h\n",
    "np.array(h.get(\"Opinion Segment Labels\").get(\"data\").get(\"03bSnISJMiM\").get(\"intervals\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\t\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = '../../data/CMU_MOSI/'\n",
    "VIDEO_PATH = os.path.join(DATA_PATH, 'Video/Segmented')\n",
    "LABELS_PATH = os.path.join(DATA_PATH, 'CMU_MOSI_Opinion_Labels.csd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_csd = h5py.File(LABELS_PATH, 'r').get(\"Opinion Segment Labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['data', 'metadata']>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_csd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2.4], dtype=float32),\n",
       " array([-0.8], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-1.75], dtype=float32),\n",
       " array([0.], dtype=float32),\n",
       " array([0.], dtype=float32),\n",
       " array([0.8], dtype=float32),\n",
       " array([0.], dtype=float32),\n",
       " array([0.2], dtype=float32),\n",
       " array([-1.2], dtype=float32),\n",
       " array([-0.5], dtype=float32),\n",
       " array([2.2], dtype=float32),\n",
       " array([1.8], dtype=float32)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = list(labels_csd[\"data\"].get(\"03bSnISJMiM\").get(\"features\"))\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.4, -0.8, -1.0, -1.75, 0.0, 0.0, 0.8, 0.0, 0.2, -1.2, -0.5, 2.2, 1.8]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.array(labels_csd[\"data\"].get(\"03bSnISJMiM\").get(\"features\"))[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Mustapha/Documents/CENTRALESUPELEC_3A/advanced AI/multimodal_sentiment_analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = %pwd\n",
    "if path.split(os.sep)[-1] == 'Perceiver':\n",
    "    %cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.data_loaders.cmu_mosi import get_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching videos for training split: 100%|██████████| 40/40 [00:04<00:00,  9.89it/s]\n",
      "Caching videos for validation split: 100%|██████████| 10/10 [00:00<00:00, 11.03it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val(batch_size=1, debugging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00205994, -0.0025177 , -0.00073242, ...,  0.        ,\n",
       "        0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[11][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38058,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[7][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PerceiverForMultimodalAutoencoding\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = PerceiverForMultimodalAutoencoding.from_pretrained(\"deepmind/multimodal-perceiver\")\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PerceiverForMultimodalAutoencoding.from_pretrained(\"deepmind/multimodal-perceiver\")\n",
    "\n",
    "# image = torch.rand(1, 16, 224, 224) # Not good\n",
    "image = torch.rand(1, 16, 3, 224, 224)\n",
    "audio =  torch.rand(1, 30720, 1)\n",
    "\n",
    "inputs = dict(\n",
    "    image = image,\n",
    "    audio =  audio,\n",
    "    label =  torch.zeros((1, 700))\n",
    ")\n",
    "\n",
    "nchunks = 128\n",
    "image_chunk_size = np.prod((16, 224, 224)) // nchunks\n",
    "audio_chunk_size = audio.shape[1] // model.config.samples_per_patch // nchunks\n",
    "\n",
    "chunk_idx = 127\n",
    "subsampling = {\n",
    "    \"image\": torch.arange(image_chunk_size * chunk_idx, image_chunk_size * (chunk_idx + 1)),\n",
    "    \"audio\": torch.arange(audio_chunk_size * chunk_idx, audio_chunk_size * (chunk_idx + 1)),\n",
    "    \"label\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.samples_per_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(inputs = inputs , subsampled_output_points=subsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_label = output.logits[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[663,  49, 199, 637, 574]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(out_label, 5).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[278, 663,  67, 354, 647]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(out_label, 5).indices"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "76a523b229c1bdfefc2e48939a50f2e7755309cd9defdafaa93eeee6ec8eda56"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('yolo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
