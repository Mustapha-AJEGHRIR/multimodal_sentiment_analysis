{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TL-ERC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-Te8AZ0M4QF",
        "outputId": "98146dfb-8092-4d4b-8c24-3068ec673665"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'conv-emotion'...\n",
            "remote: Enumerating objects: 1388, done.\u001b[K\n",
            "remote: Counting objects: 100% (324/324), done.\u001b[K\n",
            "remote: Compressing objects: 100% (225/225), done.\u001b[K\n",
            "remote: Total 1388 (delta 156), reused 218 (delta 91), pack-reused 1064\u001b[K\n",
            "Receiving objects: 100% (1388/1388), 751.31 MiB | 29.68 MiB/s, done.\n",
            "Resolving deltas: 100% (700/700), done.\n",
            "Checking out files: 100% (435/435), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/declare-lab/conv-emotion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(list(videoSentence.values())[0]))\n",
        "# print(len(list(videoLabels.values())[0]))"
      ],
      "metadata": {
        "id": "_cZqx7a6TSm0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c61070cb-947b-4523-98f8-874a987cce62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n",
            "42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/conv-emotion/TL-ERC/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdXIks9UTauY",
        "outputId": "0725f707-90c2-4951-9a7c-b0615432d61e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/conv-emotion/TL-ERC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup.py"
      ],
      "metadata": {
        "id": "awmEYIJR8v0H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making iemocap dataset in the current folder conv-emotion\\TL-ERC\\datasets"
      ],
      "metadata": {
        "id": "np1S_ES620TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Depot_Mouhamed-20220228T100527Z-001/DialogueRNN/DialogueRNN/IEMOCAP_features/IEMOCAP_features_raw.pkl /content/conv-emotion/TL-ERC/datasets"
      ],
      "metadata": {
        "id": "rumJWWo_WkEo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1nufbrBJ-LtcROv1MviCHFI7tQE3JnqQR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-12u-WQzEMfK",
        "outputId": "ba62f45a-44d1-4512-ea95-cb2645f34f7e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nufbrBJ-LtcROv1MviCHFI7tQE3JnqQR\n",
            "To: /content/conv-emotion/TL-ERC/iemocap.zip\n",
            "100% 14.2M/14.2M [00:00<00:00, 110MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/conv-emotion/TL-ERC/iemocap.zip -d /content/conv-emotion/TL-ERC/datasets"
      ],
      "metadata": {
        "id": "cMvW8y8AEhJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "store cornell weights in generative weights"
      ],
      "metadata": {
        "id": "nSK_Yt1P3D6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd generative_weights\n",
        "!gdown --id 1OXtnyJ5nDMmK75L9kEQvKPIyO0xzyeVC\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HP6NaSq9npX",
        "outputId": "983257ca-bd05-4ccc-d5ce-86eb6d44c40b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/conv-emotion/TL-ERC/generative_weights\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OXtnyJ5nDMmK75L9kEQvKPIyO0xzyeVC\n",
            "To: /content/conv-emotion/TL-ERC/generative_weights/cornell_weights.pkl\n",
            "100% 42.0M/42.0M [00:00<00:00, 175MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "%cd bert_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7pJS4i__Dqz",
        "outputId": "21fe13fd-1568-499c-b9bc-17e94acfac35"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/conv-emotion/TL-ERC\n",
            "/content/conv-emotion/TL-ERC/bert_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train the model"
      ],
      "metadata": {
        "id": "tbRQScq14iwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_pretrained_bert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3pCmId7BG8j",
        "outputId": "499c850f-cff0-4063-f473-ccec38018c1f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 21.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 17.8 MB/s eta 0:00:01\r\u001b[K     |████████                        | 30 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 123 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.10.0+cu111)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.21.20-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 41.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.21.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.63.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.10.0.2)\n",
            "Collecting botocore<1.25.0,>=1.24.20\n",
            "  Downloading botocore-1.24.20-py3-none-any.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 48.1 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.20->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 45.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.20->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 49.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2021.10.8)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.21.20 botocore-1.24.20 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.5.2 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAiOsfDNA7g4",
        "outputId": "9c76c965-7e32-4a87-8eba-178810145b7f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 125 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.5)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python train.py --load_checkpoint=../generative_weights/cornell_weights.pkl --data=iemocap"
      ],
      "metadata": {
        "id": "I-vBVoT9_PCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from solver import *\n",
        "from data_loader import get_loader\n",
        "from configs import get_config\n",
        "from util import Vocab\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "\n",
        "def load_pickle(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "\n",
        "config = get_config(parse = False, mode='train')\n",
        "val_config = get_config(parse = False, mode='valid')\n",
        "test_config = get_config(parse = False, mode='test')\n",
        "\n",
        "# _RUNS = config.runs\n",
        "\n",
        "# _best_test_loss, _best_test_f1_w, _best_test_f1_m, _best_epoch = [], [], [], []\n",
        "\n",
        "# for run in range(_RUNS):\n",
        "\n",
        "print(config)\n",
        "\n",
        "# No. of videos to consider\n",
        "training_data_len = int(config.training_percentage * \\\n",
        "    len(load_pickle(config.sentences_path)))\n",
        "\n",
        "\n",
        "train_data_loader = get_loader(\n",
        "    sentences=load_pickle(config.sentences_path)[:training_data_len],\n",
        "    labels=load_pickle(config.label_path)[:training_data_len],\n",
        "    conversation_length=load_pickle(config.conversation_length_path)[:training_data_len],\n",
        "    sentence_length=load_pickle(config.sentence_length_path)[:training_data_len],\n",
        "    batch_size=config.batch_size)\n",
        "\n",
        "eval_data_loader = get_loader(\n",
        "    sentences=load_pickle(val_config.sentences_path),\n",
        "    labels=load_pickle(val_config.label_path),\n",
        "    conversation_length=load_pickle(val_config.conversation_length_path),\n",
        "    sentence_length=load_pickle(val_config.sentence_length_path),\n",
        "    batch_size=val_config.eval_batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "test_data_loader = get_loader(\n",
        "    sentences=load_pickle(test_config.sentences_path),\n",
        "    labels=load_pickle(test_config.label_path),\n",
        "    conversation_length=load_pickle(test_config.conversation_length_path),\n",
        "    sentence_length=load_pickle(test_config.sentence_length_path),\n",
        "    batch_size=test_config.eval_batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# for testing\n",
        "solver = Solver(config, train_data_loader,\n",
        "                eval_data_loader, test_data_loader, is_train=True)\n",
        "\n",
        "\n",
        "solver.build()\n",
        "\n",
        "best_test_loss, best_test_f1_w, best_epoch = solver.train()\n",
        "\n",
        "    # print(f\"Current RUN: {run+1}\")\n",
        "\n",
        "    # print(\"\\n\\nBest test loss\")\n",
        "    # print(best_test_loss)\n",
        "    # print(\"Best test f1 weighted\")\n",
        "    # print(best_test_f1_w)\n",
        "    # print(\"Best epoch\")\n",
        "    # print(best_epoch)\n",
        "\n",
        "    # _best_test_loss.append(best_test_loss)\n",
        "    # _best_test_f1_w.append(best_test_f1_w)\n",
        "    # _best_epoch.append(best_epoch)\n",
        "\n",
        "\n",
        "# Print final\n",
        "# print(f\"\\n\\nAverage across runs:\")\n",
        "\n",
        "# print(\"Best epoch\")\n",
        "# print(_best_epoch)\n",
        "\n",
        "# print(\"\\n\\nBest test loss\")\n",
        "# print(np.mean(np.array(_best_test_loss), axis=0))\n",
        "\n",
        "# print(\"Overall test f1 weighted\")\n",
        "# print(np.array(_best_test_f1_w))\n",
        "\n",
        "# print(\"Best test f1 weighted\")\n",
        "# print(np.mean(np.array(_best_test_f1_w), axis=0))"
      ],
      "metadata": {
        "id": "bQqwzQsE_jpX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b570df-fbd5-4821-d12c-2a9762c46ad8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iemocap\n",
            "iemocap\n",
            "iemocap\n",
            "Configurations\n",
            "{'activation': 'Tanh',\n",
            " 'batch_size': 2,\n",
            " 'bidirectional': True,\n",
            " 'checkpoint': None,\n",
            " 'clip': 1.0,\n",
            " 'context_size': 256,\n",
            " 'conversation_length_path': PosixPath('/content/conv-emotion/TL-ERC/datasets/iemocap/train/conversation_length.pkl'),\n",
            " 'data': 'iemocap',\n",
            " 'data_dir': PosixPath('/content/conv-emotion/TL-ERC/datasets/iemocap/train'),\n",
            " 'dataset_dir': PosixPath('/content/conv-emotion/TL-ERC/datasets/iemocap'),\n",
            " 'dropout': 0.0,\n",
            " 'embedding_size': 300,\n",
            " 'encoder_hidden_size': 768,\n",
            " 'eval_batch_size': 2,\n",
            " 'feedforward': 'FeedForward',\n",
            " 'id2word_path': PosixPath('/content/conv-emotion/TL-ERC/datasets/iemocap/id2word.pkl'),\n",
            " 'label_path': PosixPath('/content/conv-emotion/TL-ERC/datasets/iemocap/train/labels.pkl'),\n",
            " 'learning_rate': 0.0001,\n",
            " 'load_checkpoint': None,\n",
            " 'minimum_improvement': 0.001,\n",
            " 'mode': 'train',\n",
            " 'model': 'bc_RNN',\n",
            " 'n_epoch': 500,\n",
            " 'num_bert_layers': 4,\n",
            " 'num_classes': 6,\n",
            " 'num_layers': 1,\n",
            " 'optimizer': <class 'torch.optim.adam.Adam'>,\n",
            " 'patience': 10,\n",
            " 'plot_every_epoch': 1,\n",
            " 'print_every': 100,\n",
            " 'rnn': <class 'torch.nn.modules.rnn.GRU'>,\n",
            " 'rnncell': <class 'layer.rnncells.StackedGRUCell'>,\n",
            " 'runs': 5,\n",
            " 'save_every_epoch': 1,\n",
            " 'sentence_length_path': PosixPath('/content/conv-emotion/TL-ERC/datasets/iemocap/train/sentence_length.pkl'),\n",
            " 'sentences_path': PosixPath('/content/conv-emotion/TL-ERC/datasets/iemocap/train/sentences.pkl'),\n",
            " 'train_emb': True,\n",
            " 'training_percentage': 1.0,\n",
            " 'word2id_path': PosixPath('/content/conv-emotion/TL-ERC/datasets/iemocap/word2id.pkl'),\n",
            " 'word_emb_path': PosixPath('/content/conv-emotion/TL-ERC/datasets/iemocap/word_emb.pkl')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 2001234.38B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build Graph\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407873900/407873900 [00:11<00:00, 36930478.35B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter initiailization\n",
            "\tcontext_encoder.rnn.weight_hh_l0\n",
            "\tencoder.embeddings.word_embeddings.weight True\n",
            "\tencoder.embeddings.position_embeddings.weight True\n",
            "\tencoder.embeddings.token_type_embeddings.weight True\n",
            "\tencoder.embeddings.LayerNorm.weight True\n",
            "\tencoder.embeddings.LayerNorm.bias True\n",
            "\tencoder.encoder.layer.0.attention.self.query.weight True\n",
            "\tencoder.encoder.layer.0.attention.self.query.bias True\n",
            "\tencoder.encoder.layer.0.attention.self.key.weight True\n",
            "\tencoder.encoder.layer.0.attention.self.key.bias True\n",
            "\tencoder.encoder.layer.0.attention.self.value.weight True\n",
            "\tencoder.encoder.layer.0.attention.self.value.bias True\n",
            "\tencoder.encoder.layer.0.attention.output.dense.weight True\n",
            "\tencoder.encoder.layer.0.attention.output.dense.bias True\n",
            "\tencoder.encoder.layer.0.attention.output.LayerNorm.weight True\n",
            "\tencoder.encoder.layer.0.attention.output.LayerNorm.bias True\n",
            "\tencoder.encoder.layer.0.intermediate.dense.weight True\n",
            "\tencoder.encoder.layer.0.intermediate.dense.bias True\n",
            "\tencoder.encoder.layer.0.output.dense.weight True\n",
            "\tencoder.encoder.layer.0.output.dense.bias True\n",
            "\tencoder.encoder.layer.0.output.LayerNorm.weight True\n",
            "\tencoder.encoder.layer.0.output.LayerNorm.bias True\n",
            "\tencoder.encoder.layer.1.attention.self.query.weight True\n",
            "\tencoder.encoder.layer.1.attention.self.query.bias True\n",
            "\tencoder.encoder.layer.1.attention.self.key.weight True\n",
            "\tencoder.encoder.layer.1.attention.self.key.bias True\n",
            "\tencoder.encoder.layer.1.attention.self.value.weight True\n",
            "\tencoder.encoder.layer.1.attention.self.value.bias True\n",
            "\tencoder.encoder.layer.1.attention.output.dense.weight True\n",
            "\tencoder.encoder.layer.1.attention.output.dense.bias True\n",
            "\tencoder.encoder.layer.1.attention.output.LayerNorm.weight True\n",
            "\tencoder.encoder.layer.1.attention.output.LayerNorm.bias True\n",
            "\tencoder.encoder.layer.1.intermediate.dense.weight True\n",
            "\tencoder.encoder.layer.1.intermediate.dense.bias True\n",
            "\tencoder.encoder.layer.1.output.dense.weight True\n",
            "\tencoder.encoder.layer.1.output.dense.bias True\n",
            "\tencoder.encoder.layer.1.output.LayerNorm.weight True\n",
            "\tencoder.encoder.layer.1.output.LayerNorm.bias True\n",
            "\tencoder.encoder.layer.2.attention.self.query.weight True\n",
            "\tencoder.encoder.layer.2.attention.self.query.bias True\n",
            "\tencoder.encoder.layer.2.attention.self.key.weight True\n",
            "\tencoder.encoder.layer.2.attention.self.key.bias True\n",
            "\tencoder.encoder.layer.2.attention.self.value.weight True\n",
            "\tencoder.encoder.layer.2.attention.self.value.bias True\n",
            "\tencoder.encoder.layer.2.attention.output.dense.weight True\n",
            "\tencoder.encoder.layer.2.attention.output.dense.bias True\n",
            "\tencoder.encoder.layer.2.attention.output.LayerNorm.weight True\n",
            "\tencoder.encoder.layer.2.attention.output.LayerNorm.bias True\n",
            "\tencoder.encoder.layer.2.intermediate.dense.weight True\n",
            "\tencoder.encoder.layer.2.intermediate.dense.bias True\n",
            "\tencoder.encoder.layer.2.output.dense.weight True\n",
            "\tencoder.encoder.layer.2.output.dense.bias True\n",
            "\tencoder.encoder.layer.2.output.LayerNorm.weight True\n",
            "\tencoder.encoder.layer.2.output.LayerNorm.bias True\n",
            "\tencoder.encoder.layer.3.attention.self.query.weight True\n",
            "\tencoder.encoder.layer.3.attention.self.query.bias True\n",
            "\tencoder.encoder.layer.3.attention.self.key.weight True\n",
            "\tencoder.encoder.layer.3.attention.self.key.bias True\n",
            "\tencoder.encoder.layer.3.attention.self.value.weight True\n",
            "\tencoder.encoder.layer.3.attention.self.value.bias True\n",
            "\tencoder.encoder.layer.3.attention.output.dense.weight True\n",
            "\tencoder.encoder.layer.3.attention.output.dense.bias True\n",
            "\tencoder.encoder.layer.3.attention.output.LayerNorm.weight True\n",
            "\tencoder.encoder.layer.3.attention.output.LayerNorm.bias True\n",
            "\tencoder.encoder.layer.3.intermediate.dense.weight True\n",
            "\tencoder.encoder.layer.3.intermediate.dense.bias True\n",
            "\tencoder.encoder.layer.3.output.dense.weight True\n",
            "\tencoder.encoder.layer.3.output.dense.bias True\n",
            "\tencoder.encoder.layer.3.output.LayerNorm.weight True\n",
            "\tencoder.encoder.layer.3.output.LayerNorm.bias True\n",
            "\tencoder.encoder.layer.4.attention.self.query.weight False\n",
            "\tencoder.encoder.layer.4.attention.self.query.bias False\n",
            "\tencoder.encoder.layer.4.attention.self.key.weight False\n",
            "\tencoder.encoder.layer.4.attention.self.key.bias False\n",
            "\tencoder.encoder.layer.4.attention.self.value.weight False\n",
            "\tencoder.encoder.layer.4.attention.self.value.bias False\n",
            "\tencoder.encoder.layer.4.attention.output.dense.weight False\n",
            "\tencoder.encoder.layer.4.attention.output.dense.bias False\n",
            "\tencoder.encoder.layer.4.attention.output.LayerNorm.weight False\n",
            "\tencoder.encoder.layer.4.attention.output.LayerNorm.bias False\n",
            "\tencoder.encoder.layer.4.intermediate.dense.weight False\n",
            "\tencoder.encoder.layer.4.intermediate.dense.bias False\n",
            "\tencoder.encoder.layer.4.output.dense.weight False\n",
            "\tencoder.encoder.layer.4.output.dense.bias False\n",
            "\tencoder.encoder.layer.4.output.LayerNorm.weight False\n",
            "\tencoder.encoder.layer.4.output.LayerNorm.bias False\n",
            "\tencoder.encoder.layer.5.attention.self.query.weight False\n",
            "\tencoder.encoder.layer.5.attention.self.query.bias False\n",
            "\tencoder.encoder.layer.5.attention.self.key.weight False\n",
            "\tencoder.encoder.layer.5.attention.self.key.bias False\n",
            "\tencoder.encoder.layer.5.attention.self.value.weight False\n",
            "\tencoder.encoder.layer.5.attention.self.value.bias False\n",
            "\tencoder.encoder.layer.5.attention.output.dense.weight False\n",
            "\tencoder.encoder.layer.5.attention.output.dense.bias False\n",
            "\tencoder.encoder.layer.5.attention.output.LayerNorm.weight False\n",
            "\tencoder.encoder.layer.5.attention.output.LayerNorm.bias False\n",
            "\tencoder.encoder.layer.5.intermediate.dense.weight False\n",
            "\tencoder.encoder.layer.5.intermediate.dense.bias False\n",
            "\tencoder.encoder.layer.5.output.dense.weight False\n",
            "\tencoder.encoder.layer.5.output.dense.bias False\n",
            "\tencoder.encoder.layer.5.output.LayerNorm.weight False\n",
            "\tencoder.encoder.layer.5.output.LayerNorm.bias False\n",
            "\tencoder.encoder.layer.6.attention.self.query.weight False\n",
            "\tencoder.encoder.layer.6.attention.self.query.bias False\n",
            "\tencoder.encoder.layer.6.attention.self.key.weight False\n",
            "\tencoder.encoder.layer.6.attention.self.key.bias False\n",
            "\tencoder.encoder.layer.6.attention.self.value.weight False\n",
            "\tencoder.encoder.layer.6.attention.self.value.bias False\n",
            "\tencoder.encoder.layer.6.attention.output.dense.weight False\n",
            "\tencoder.encoder.layer.6.attention.output.dense.bias False\n",
            "\tencoder.encoder.layer.6.attention.output.LayerNorm.weight False\n",
            "\tencoder.encoder.layer.6.attention.output.LayerNorm.bias False\n",
            "\tencoder.encoder.layer.6.intermediate.dense.weight False\n",
            "\tencoder.encoder.layer.6.intermediate.dense.bias False\n",
            "\tencoder.encoder.layer.6.output.dense.weight False\n",
            "\tencoder.encoder.layer.6.output.dense.bias False\n",
            "\tencoder.encoder.layer.6.output.LayerNorm.weight False\n",
            "\tencoder.encoder.layer.6.output.LayerNorm.bias False\n",
            "\tencoder.encoder.layer.7.attention.self.query.weight False\n",
            "\tencoder.encoder.layer.7.attention.self.query.bias False\n",
            "\tencoder.encoder.layer.7.attention.self.key.weight False\n",
            "\tencoder.encoder.layer.7.attention.self.key.bias False\n",
            "\tencoder.encoder.layer.7.attention.self.value.weight False\n",
            "\tencoder.encoder.layer.7.attention.self.value.bias False\n",
            "\tencoder.encoder.layer.7.attention.output.dense.weight False\n",
            "\tencoder.encoder.layer.7.attention.output.dense.bias False\n",
            "\tencoder.encoder.layer.7.attention.output.LayerNorm.weight False\n",
            "\tencoder.encoder.layer.7.attention.output.LayerNorm.bias False\n",
            "\tencoder.encoder.layer.7.intermediate.dense.weight False\n",
            "\tencoder.encoder.layer.7.intermediate.dense.bias False\n",
            "\tencoder.encoder.layer.7.output.dense.weight False\n",
            "\tencoder.encoder.layer.7.output.dense.bias False\n",
            "\tencoder.encoder.layer.7.output.LayerNorm.weight False\n",
            "\tencoder.encoder.layer.7.output.LayerNorm.bias False\n",
            "\tencoder.encoder.layer.8.attention.self.query.weight False\n",
            "\tencoder.encoder.layer.8.attention.self.query.bias False\n",
            "\tencoder.encoder.layer.8.attention.self.key.weight False\n",
            "\tencoder.encoder.layer.8.attention.self.key.bias False\n",
            "\tencoder.encoder.layer.8.attention.self.value.weight False\n",
            "\tencoder.encoder.layer.8.attention.self.value.bias False\n",
            "\tencoder.encoder.layer.8.attention.output.dense.weight False\n",
            "\tencoder.encoder.layer.8.attention.output.dense.bias False\n",
            "\tencoder.encoder.layer.8.attention.output.LayerNorm.weight False\n",
            "\tencoder.encoder.layer.8.attention.output.LayerNorm.bias False\n",
            "\tencoder.encoder.layer.8.intermediate.dense.weight False\n",
            "\tencoder.encoder.layer.8.intermediate.dense.bias False\n",
            "\tencoder.encoder.layer.8.output.dense.weight False\n",
            "\tencoder.encoder.layer.8.output.dense.bias False\n",
            "\tencoder.encoder.layer.8.output.LayerNorm.weight False\n",
            "\tencoder.encoder.layer.8.output.LayerNorm.bias False\n",
            "\tencoder.encoder.layer.9.attention.self.query.weight False\n",
            "\tencoder.encoder.layer.9.attention.self.query.bias False\n",
            "\tencoder.encoder.layer.9.attention.self.key.weight False\n",
            "\tencoder.encoder.layer.9.attention.self.key.bias False\n",
            "\tencoder.encoder.layer.9.attention.self.value.weight False\n",
            "\tencoder.encoder.layer.9.attention.self.value.bias False\n",
            "\tencoder.encoder.layer.9.attention.output.dense.weight False\n",
            "\tencoder.encoder.layer.9.attention.output.dense.bias False\n",
            "\tencoder.encoder.layer.9.attention.output.LayerNorm.weight False\n",
            "\tencoder.encoder.layer.9.attention.output.LayerNorm.bias False\n",
            "\tencoder.encoder.layer.9.intermediate.dense.weight False\n",
            "\tencoder.encoder.layer.9.intermediate.dense.bias False\n",
            "\tencoder.encoder.layer.9.output.dense.weight False\n",
            "\tencoder.encoder.layer.9.output.dense.bias False\n",
            "\tencoder.encoder.layer.9.output.LayerNorm.weight False\n",
            "\tencoder.encoder.layer.9.output.LayerNorm.bias False\n",
            "\tencoder.encoder.layer.10.attention.self.query.weight False\n",
            "\tencoder.encoder.layer.10.attention.self.query.bias False\n",
            "\tencoder.encoder.layer.10.attention.self.key.weight False\n",
            "\tencoder.encoder.layer.10.attention.self.key.bias False\n",
            "\tencoder.encoder.layer.10.attention.self.value.weight False\n",
            "\tencoder.encoder.layer.10.attention.self.value.bias False\n",
            "\tencoder.encoder.layer.10.attention.output.dense.weight False\n",
            "\tencoder.encoder.layer.10.attention.output.dense.bias False\n",
            "\tencoder.encoder.layer.10.attention.output.LayerNorm.weight False\n",
            "\tencoder.encoder.layer.10.attention.output.LayerNorm.bias False\n",
            "\tencoder.encoder.layer.10.intermediate.dense.weight False\n",
            "\tencoder.encoder.layer.10.intermediate.dense.bias False\n",
            "\tencoder.encoder.layer.10.output.dense.weight False\n",
            "\tencoder.encoder.layer.10.output.dense.bias False\n",
            "\tencoder.encoder.layer.10.output.LayerNorm.weight False\n",
            "\tencoder.encoder.layer.10.output.LayerNorm.bias False\n",
            "\tencoder.encoder.layer.11.attention.self.query.weight False\n",
            "\tencoder.encoder.layer.11.attention.self.query.bias False\n",
            "\tencoder.encoder.layer.11.attention.self.key.weight False\n",
            "\tencoder.encoder.layer.11.attention.self.key.bias False\n",
            "\tencoder.encoder.layer.11.attention.self.value.weight False\n",
            "\tencoder.encoder.layer.11.attention.self.value.bias False\n",
            "\tencoder.encoder.layer.11.attention.output.dense.weight False\n",
            "\tencoder.encoder.layer.11.attention.output.dense.bias False\n",
            "\tencoder.encoder.layer.11.attention.output.LayerNorm.weight False\n",
            "\tencoder.encoder.layer.11.attention.output.LayerNorm.bias False\n",
            "\tencoder.encoder.layer.11.intermediate.dense.weight False\n",
            "\tencoder.encoder.layer.11.intermediate.dense.bias False\n",
            "\tencoder.encoder.layer.11.output.dense.weight False\n",
            "\tencoder.encoder.layer.11.output.dense.bias False\n",
            "\tencoder.encoder.layer.11.output.LayerNorm.weight False\n",
            "\tencoder.encoder.layer.11.output.LayerNorm.bias False\n",
            "\tencoder.pooler.dense.weight True\n",
            "\tencoder.pooler.dense.bias True\n",
            "\tcontext_encoder.rnn.weight_ih_l0 True\n",
            "\tcontext_encoder.rnn.weight_hh_l0 True\n",
            "\tcontext_encoder.rnn.bias_ih_l0 True\n",
            "\tcontext_encoder.rnn.bias_hh_l0 True\n",
            "\tcontext2decoder.linears.0.weight True\n",
            "\tcontext2decoder.linears.0.bias True\n",
            "\tdecoder2output.linears.0.weight True\n",
            "\tdecoder2output.linears.0.bias True\n",
            "Model Parameters\n",
            "\tencoder.embeddings.word_embeddings.weight\t [30522, 768]\n",
            "\tencoder.embeddings.position_embeddings.weight\t [512, 768]\n",
            "\tencoder.embeddings.token_type_embeddings.weight\t [2, 768]\n",
            "\tencoder.embeddings.LayerNorm.weight\t [768]\n",
            "\tencoder.embeddings.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.0.attention.self.query.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.0.attention.self.query.bias\t [768]\n",
            "\tencoder.encoder.layer.0.attention.self.key.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.0.attention.self.key.bias\t [768]\n",
            "\tencoder.encoder.layer.0.attention.self.value.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.0.attention.self.value.bias\t [768]\n",
            "\tencoder.encoder.layer.0.attention.output.dense.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.0.attention.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.0.attention.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.0.attention.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.0.intermediate.dense.weight\t [3072, 768]\n",
            "\tencoder.encoder.layer.0.intermediate.dense.bias\t [3072]\n",
            "\tencoder.encoder.layer.0.output.dense.weight\t [768, 3072]\n",
            "\tencoder.encoder.layer.0.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.0.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.0.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.1.attention.self.query.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.1.attention.self.query.bias\t [768]\n",
            "\tencoder.encoder.layer.1.attention.self.key.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.1.attention.self.key.bias\t [768]\n",
            "\tencoder.encoder.layer.1.attention.self.value.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.1.attention.self.value.bias\t [768]\n",
            "\tencoder.encoder.layer.1.attention.output.dense.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.1.attention.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.1.attention.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.1.attention.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.1.intermediate.dense.weight\t [3072, 768]\n",
            "\tencoder.encoder.layer.1.intermediate.dense.bias\t [3072]\n",
            "\tencoder.encoder.layer.1.output.dense.weight\t [768, 3072]\n",
            "\tencoder.encoder.layer.1.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.1.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.1.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.2.attention.self.query.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.2.attention.self.query.bias\t [768]\n",
            "\tencoder.encoder.layer.2.attention.self.key.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.2.attention.self.key.bias\t [768]\n",
            "\tencoder.encoder.layer.2.attention.self.value.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.2.attention.self.value.bias\t [768]\n",
            "\tencoder.encoder.layer.2.attention.output.dense.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.2.attention.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.2.attention.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.2.attention.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.2.intermediate.dense.weight\t [3072, 768]\n",
            "\tencoder.encoder.layer.2.intermediate.dense.bias\t [3072]\n",
            "\tencoder.encoder.layer.2.output.dense.weight\t [768, 3072]\n",
            "\tencoder.encoder.layer.2.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.2.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.2.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.3.attention.self.query.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.3.attention.self.query.bias\t [768]\n",
            "\tencoder.encoder.layer.3.attention.self.key.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.3.attention.self.key.bias\t [768]\n",
            "\tencoder.encoder.layer.3.attention.self.value.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.3.attention.self.value.bias\t [768]\n",
            "\tencoder.encoder.layer.3.attention.output.dense.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.3.attention.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.3.attention.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.3.attention.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.3.intermediate.dense.weight\t [3072, 768]\n",
            "\tencoder.encoder.layer.3.intermediate.dense.bias\t [3072]\n",
            "\tencoder.encoder.layer.3.output.dense.weight\t [768, 3072]\n",
            "\tencoder.encoder.layer.3.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.3.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.3.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.4.attention.self.query.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.4.attention.self.query.bias\t [768]\n",
            "\tencoder.encoder.layer.4.attention.self.key.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.4.attention.self.key.bias\t [768]\n",
            "\tencoder.encoder.layer.4.attention.self.value.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.4.attention.self.value.bias\t [768]\n",
            "\tencoder.encoder.layer.4.attention.output.dense.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.4.attention.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.4.attention.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.4.attention.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.4.intermediate.dense.weight\t [3072, 768]\n",
            "\tencoder.encoder.layer.4.intermediate.dense.bias\t [3072]\n",
            "\tencoder.encoder.layer.4.output.dense.weight\t [768, 3072]\n",
            "\tencoder.encoder.layer.4.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.4.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.4.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.5.attention.self.query.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.5.attention.self.query.bias\t [768]\n",
            "\tencoder.encoder.layer.5.attention.self.key.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.5.attention.self.key.bias\t [768]\n",
            "\tencoder.encoder.layer.5.attention.self.value.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.5.attention.self.value.bias\t [768]\n",
            "\tencoder.encoder.layer.5.attention.output.dense.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.5.attention.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.5.attention.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.5.attention.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.5.intermediate.dense.weight\t [3072, 768]\n",
            "\tencoder.encoder.layer.5.intermediate.dense.bias\t [3072]\n",
            "\tencoder.encoder.layer.5.output.dense.weight\t [768, 3072]\n",
            "\tencoder.encoder.layer.5.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.5.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.5.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.6.attention.self.query.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.6.attention.self.query.bias\t [768]\n",
            "\tencoder.encoder.layer.6.attention.self.key.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.6.attention.self.key.bias\t [768]\n",
            "\tencoder.encoder.layer.6.attention.self.value.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.6.attention.self.value.bias\t [768]\n",
            "\tencoder.encoder.layer.6.attention.output.dense.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.6.attention.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.6.attention.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.6.attention.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.6.intermediate.dense.weight\t [3072, 768]\n",
            "\tencoder.encoder.layer.6.intermediate.dense.bias\t [3072]\n",
            "\tencoder.encoder.layer.6.output.dense.weight\t [768, 3072]\n",
            "\tencoder.encoder.layer.6.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.6.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.6.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.7.attention.self.query.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.7.attention.self.query.bias\t [768]\n",
            "\tencoder.encoder.layer.7.attention.self.key.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.7.attention.self.key.bias\t [768]\n",
            "\tencoder.encoder.layer.7.attention.self.value.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.7.attention.self.value.bias\t [768]\n",
            "\tencoder.encoder.layer.7.attention.output.dense.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.7.attention.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.7.attention.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.7.attention.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.7.intermediate.dense.weight\t [3072, 768]\n",
            "\tencoder.encoder.layer.7.intermediate.dense.bias\t [3072]\n",
            "\tencoder.encoder.layer.7.output.dense.weight\t [768, 3072]\n",
            "\tencoder.encoder.layer.7.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.7.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.7.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.8.attention.self.query.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.8.attention.self.query.bias\t [768]\n",
            "\tencoder.encoder.layer.8.attention.self.key.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.8.attention.self.key.bias\t [768]\n",
            "\tencoder.encoder.layer.8.attention.self.value.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.8.attention.self.value.bias\t [768]\n",
            "\tencoder.encoder.layer.8.attention.output.dense.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.8.attention.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.8.attention.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.8.attention.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.8.intermediate.dense.weight\t [3072, 768]\n",
            "\tencoder.encoder.layer.8.intermediate.dense.bias\t [3072]\n",
            "\tencoder.encoder.layer.8.output.dense.weight\t [768, 3072]\n",
            "\tencoder.encoder.layer.8.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.8.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.8.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.9.attention.self.query.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.9.attention.self.query.bias\t [768]\n",
            "\tencoder.encoder.layer.9.attention.self.key.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.9.attention.self.key.bias\t [768]\n",
            "\tencoder.encoder.layer.9.attention.self.value.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.9.attention.self.value.bias\t [768]\n",
            "\tencoder.encoder.layer.9.attention.output.dense.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.9.attention.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.9.attention.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.9.attention.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.9.intermediate.dense.weight\t [3072, 768]\n",
            "\tencoder.encoder.layer.9.intermediate.dense.bias\t [3072]\n",
            "\tencoder.encoder.layer.9.output.dense.weight\t [768, 3072]\n",
            "\tencoder.encoder.layer.9.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.9.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.9.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.10.attention.self.query.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.10.attention.self.query.bias\t [768]\n",
            "\tencoder.encoder.layer.10.attention.self.key.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.10.attention.self.key.bias\t [768]\n",
            "\tencoder.encoder.layer.10.attention.self.value.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.10.attention.self.value.bias\t [768]\n",
            "\tencoder.encoder.layer.10.attention.output.dense.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.10.attention.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.10.attention.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.10.attention.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.10.intermediate.dense.weight\t [3072, 768]\n",
            "\tencoder.encoder.layer.10.intermediate.dense.bias\t [3072]\n",
            "\tencoder.encoder.layer.10.output.dense.weight\t [768, 3072]\n",
            "\tencoder.encoder.layer.10.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.10.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.10.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.11.attention.self.query.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.11.attention.self.query.bias\t [768]\n",
            "\tencoder.encoder.layer.11.attention.self.key.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.11.attention.self.key.bias\t [768]\n",
            "\tencoder.encoder.layer.11.attention.self.value.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.11.attention.self.value.bias\t [768]\n",
            "\tencoder.encoder.layer.11.attention.output.dense.weight\t [768, 768]\n",
            "\tencoder.encoder.layer.11.attention.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.11.attention.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.11.attention.output.LayerNorm.bias\t [768]\n",
            "\tencoder.encoder.layer.11.intermediate.dense.weight\t [3072, 768]\n",
            "\tencoder.encoder.layer.11.intermediate.dense.bias\t [3072]\n",
            "\tencoder.encoder.layer.11.output.dense.weight\t [768, 3072]\n",
            "\tencoder.encoder.layer.11.output.dense.bias\t [768]\n",
            "\tencoder.encoder.layer.11.output.LayerNorm.weight\t [768]\n",
            "\tencoder.encoder.layer.11.output.LayerNorm.bias\t [768]\n",
            "\tencoder.pooler.dense.weight\t [768, 768]\n",
            "\tencoder.pooler.dense.bias\t [768]\n",
            "\tcontext_encoder.rnn.weight_ih_l0\t [768, 768]\n",
            "\tcontext_encoder.rnn.weight_hh_l0\t [768, 256]\n",
            "\tcontext_encoder.rnn.bias_ih_l0\t [768]\n",
            "\tcontext_encoder.rnn.bias_hh_l0\t [768]\n",
            "\tcontext2decoder.linears.0.weight\t [256, 256]\n",
            "\tcontext2decoder.linears.0.bias\t [256]\n",
            "\tdecoder2output.linears.0.weight\t [6, 256]\n",
            "\tdecoder2output.linears.0.bias\t [6]\n",
            "Done! It took 2e+01 secs\n",
            "\n",
            "Training Start!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|                                                    | 0/48 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, iter 0: loss = 1.7651441097259521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████| 48/48 [00:30<00:00,  1.55it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss average: 1.793\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000       376\n",
            "           1     0.1843    0.1937    0.1889       764\n",
            "           2     0.2538    0.1833    0.2129      1080\n",
            "           3     0.1111    0.0080    0.0149       749\n",
            "           4     0.0000    0.0000    0.0000       520\n",
            "           5     0.2600    0.6579    0.3727      1210\n",
            "\n",
            "    accuracy                         0.2443      4699\n",
            "   macro avg     0.1349    0.1738    0.1316      4699\n",
            "weighted avg     0.1730    0.2443    0.1780      4699\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000       144\n",
            "           1     0.0000    0.0000    0.0000       245\n",
            "           2     0.0000    0.0000    0.0000       384\n",
            "           3     0.0000    0.0000    0.0000       170\n",
            "           4     0.0000    0.0000    0.0000       299\n",
            "           5     0.2348    1.0000    0.3802       381\n",
            "\n",
            "    accuracy                         0.2348      1623\n",
            "   macro avg     0.0391    0.1667    0.0634      1623\n",
            "weighted avg     0.0551    0.2348    0.0893      1623\n",
            "\n",
            "1.7930196871360142 0.17798736782663668 0.08752898664592536 0.0892614032563339\n",
            "Patience counter: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|                                                    | 0/48 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2, iter 0: loss = 1.791110873222351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████| 48/48 [00:31<00:00,  1.51it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 loss average: 1.748\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000       376\n",
            "           1     0.0000    0.0000    0.0000       764\n",
            "           2     0.2534    0.2417    0.2474      1080\n",
            "           3     0.0000    0.0000    0.0000       749\n",
            "           4     0.0000    0.0000    0.0000       520\n",
            "           5     0.2811    0.8521    0.4227      1210\n",
            "\n",
            "    accuracy                         0.2750      4699\n",
            "   macro avg     0.0891    0.1823    0.1117      4699\n",
            "weighted avg     0.1306    0.2750    0.1657      4699\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000       144\n",
            "           1     0.0000    0.0000    0.0000       245\n",
            "           2     0.3257    0.4844    0.3895       384\n",
            "           3     0.0000    0.0000    0.0000       170\n",
            "           4     0.0000    0.0000    0.0000       299\n",
            "           5     0.3156    0.8714    0.4634       381\n",
            "\n",
            "    accuracy                         0.3192      1623\n",
            "   macro avg     0.1069    0.2260    0.1421      1623\n",
            "weighted avg     0.1512    0.3192    0.2009      1623\n",
            "\n",
            "1.7481646661957104 0.16570952308264972 0.17267531242348386 0.20093689394679146\n",
            "Patience counter: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▉                                           | 1/48 [00:00<00:15,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3, iter 0: loss = 1.4691966772079468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████| 48/48 [00:31<00:00,  1.55it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 loss average: 1.654\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000       376\n",
            "           1     0.2286    0.0105    0.0200       764\n",
            "           2     0.3077    0.5361    0.3910      1080\n",
            "           3     0.7838    0.0387    0.0738       749\n",
            "           4     0.6162    0.1173    0.1971       520\n",
            "           5     0.3205    0.7008    0.4398      1210\n",
            "\n",
            "    accuracy                         0.3245      4699\n",
            "   macro avg     0.3761    0.2339    0.1869      4699\n",
            "weighted avg     0.3835    0.3245    0.2399      4699\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000       144\n",
            "           1     0.5098    0.1061    0.1757       245\n",
            "           2     0.4222    0.0990    0.1603       384\n",
            "           3     0.6429    0.1588    0.2547       170\n",
            "           4     0.2707    0.9298    0.4193       299\n",
            "           5     0.5206    0.5643    0.5416       381\n",
            "\n",
            "    accuracy                         0.3598      1623\n",
            "   macro avg     0.3944    0.3097    0.2586      1623\n",
            "weighted avg     0.4163    0.3598    0.2955      1623\n",
            "\n",
            "1.6544036492705345 0.23994129005902534 0.25271073981397496 0.29551423857068654\n",
            "Patience counter: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▉                                           | 1/48 [00:00<00:21,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4, iter 0: loss = 1.5345808267593384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████| 48/48 [00:30<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 loss average: 1.402\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.3333    0.0027    0.0053       376\n",
            "           1     0.6899    0.1427    0.2364       764\n",
            "           2     0.3452    0.5306    0.4182      1080\n",
            "           3     0.6265    0.4299    0.5099       749\n",
            "           4     0.3653    0.4538    0.4048       520\n",
            "           5     0.4709    0.6686    0.5526      1210\n",
            "\n",
            "    accuracy                         0.4363      4699\n",
            "   macro avg     0.4718    0.3714    0.3545      4699\n",
            "weighted avg     0.4797    0.4363    0.4034      4699\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000       144\n",
            "           1     0.3590    0.8000    0.4956       245\n",
            "           2     0.5709    0.4193    0.4835       384\n",
            "           3     0.5525    0.5882    0.5698       170\n",
            "           4     0.6089    0.5518    0.5789       299\n",
            "           5     0.5977    0.5381    0.5663       381\n",
            "\n",
            "    accuracy                         0.5096      1623\n",
            "   macro avg     0.4482    0.4829    0.4490      1623\n",
            "weighted avg     0.4996    0.5096    0.4885      1623\n",
            "\n",
            "1.4017520522077878 0.4033592942659332 0.37423847662943277 0.48848097066757634\n",
            "Patience counter: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|                                                    | 0/48 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5, iter 0: loss = 0.9084632992744446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████| 48/48 [00:30<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 loss average: 1.131\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.0027    0.0053       376\n",
            "           1     0.5137    0.6623    0.5786       764\n",
            "           2     0.5625    0.5000    0.5294      1080\n",
            "           3     0.6671    0.6182    0.6417       749\n",
            "           4     0.4992    0.6115    0.5497       520\n",
            "           5     0.5942    0.6983    0.6421      1210\n",
            "\n",
            "    accuracy                         0.5688      4699\n",
            "   macro avg     0.6395    0.5155    0.4911      4699\n",
            "weighted avg     0.6074    0.5688    0.5446      4699\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000       144\n",
            "           1     0.6784    0.5510    0.6081       245\n",
            "           2     0.4424    0.7604    0.5594       384\n",
            "           3     0.7921    0.4706    0.5904       170\n",
            "           4     0.6020    0.6020    0.6020       299\n",
            "           5     0.5989    0.5722    0.5852       381\n",
            "\n",
            "    accuracy                         0.5576      1623\n",
            "   macro avg     0.5190    0.4927    0.4909      1623\n",
            "weighted avg     0.5415    0.5576    0.5343      1623\n",
            "\n",
            "1.1313202679157257 0.5446371447479054 0.4418520332235851 0.5342788567603007\n",
            "Patience counter: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|                                                    | 0/48 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6, iter 0: loss = 1.0233433246612549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████| 48/48 [00:31<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 loss average: 0.915\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4660    0.2367    0.3139       376\n",
            "           1     0.7297    0.7526    0.7410       764\n",
            "           2     0.6243    0.6648    0.6439      1080\n",
            "           3     0.7332    0.5834    0.6498       749\n",
            "           4     0.5658    0.6865    0.6203       520\n",
            "           5     0.6672    0.7405    0.7019      1210\n",
            "\n",
            "    accuracy                         0.6538      4699\n",
            "   macro avg     0.6310    0.6108    0.6118      4699\n",
            "weighted avg     0.6507    0.6538    0.6466      4699\n",
            "\n",
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5806    0.1250    0.2057       144\n",
            "           1     0.4987    0.7796    0.6083       245\n",
            "           2     0.5280    0.6146    0.5680       384\n",
            "           3     0.5652    0.6118    0.5876       170\n",
            "           4     0.6125    0.5920    0.6020       299\n",
            "           5     0.6401    0.4856    0.5522       381\n",
            "\n",
            "    accuracy                         0.5613      1623\n",
            "   macro avg     0.5709    0.5347    0.5206      1623\n",
            "weighted avg     0.5740    0.5613    0.5466      1623\n",
            "\n",
            "0.9151580122609934 0.6465660257187167 0.4510338535029121 0.546555771791937\n",
            "Patience counter: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|                                                    | 0/48 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7, iter 0: loss = 0.7726355195045471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████| 48/48 [00:30<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 loss average: 0.764\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5066    0.3085    0.3835       376\n",
            "           1     0.8184    0.8495    0.8337       764\n",
            "           2     0.7231    0.7231    0.7231      1080\n",
            "           3     0.7961    0.6569    0.7198       749\n",
            "           4     0.5585    0.7250    0.6310       520\n",
            "           5     0.7239    0.7802    0.7510      1210\n",
            "\n",
            "    accuracy                         0.7148      4699\n",
            "   macro avg     0.6878    0.6739    0.6737      4699\n",
            "weighted avg     0.7149    0.7148    0.7104      4699\n",
            "\n",
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4667    0.3403    0.3936       144\n",
            "           1     0.4545    0.7755    0.5732       245\n",
            "           2     0.4702    0.6380    0.5414       384\n",
            "           3     0.5490    0.6588    0.5989       170\n",
            "           4     0.7237    0.3679    0.4878       299\n",
            "           5     0.6861    0.4016    0.5066       381\n",
            "\n",
            "    accuracy                         0.5293      1623\n",
            "   macro avg     0.5584    0.5304    0.5169      1623\n",
            "weighted avg     0.5732    0.5293    0.5211      1623\n",
            "\n",
            "0.7640716737757126 0.7103744019479057 0.45191662689576223 0.521074333298277\n",
            "Patience counter: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▉                                           | 1/48 [00:00<00:22,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8, iter 0: loss = 0.7496408224105835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████| 48/48 [00:31<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 loss average: 0.679\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5044    0.4548    0.4783       376\n",
            "           1     0.8452    0.8573    0.8512       764\n",
            "           2     0.7400    0.7880    0.7632      1080\n",
            "           3     0.7693    0.7303    0.7493       749\n",
            "           4     0.6230    0.6135    0.6182       520\n",
            "           5     0.7739    0.7752    0.7746      1210\n",
            "\n",
            "    accuracy                         0.7408      4699\n",
            "   macro avg     0.7093    0.7032    0.7058      4699\n",
            "weighted avg     0.7387    0.7408    0.7394      4699\n",
            "\n",
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6739    0.2153    0.3263       144\n",
            "           1     0.4879    0.7388    0.5877       245\n",
            "           2     0.4841    0.5938    0.5333       384\n",
            "           3     0.6250    0.6176    0.6213       170\n",
            "           4     0.7207    0.4314    0.5397       299\n",
            "           5     0.6005    0.6115    0.6060       381\n",
            "\n",
            "    accuracy                         0.5588      1623\n",
            "   macro avg     0.5987    0.5347    0.5357      1623\n",
            "weighted avg     0.5872    0.5588    0.5506      1623\n",
            "\n",
            "0.6792569222549597 0.7393891515584347 0.45866416899194173 0.5506174055109307\n",
            "Patience counter: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▉                                           | 1/48 [00:00<00:17,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9, iter 0: loss = 0.36230897903442383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████| 48/48 [00:31<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 loss average: 0.583\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6962    0.4814    0.5692       376\n",
            "           1     0.8450    0.8848    0.8645       764\n",
            "           2     0.7996    0.8019    0.8007      1080\n",
            "           3     0.7942    0.8037    0.7989       749\n",
            "           4     0.7238    0.8115    0.7652       520\n",
            "           5     0.8066    0.8099    0.8082      1210\n",
            "\n",
            "    accuracy                         0.7931      4699\n",
            "   macro avg     0.7776    0.7655    0.7678      4699\n",
            "weighted avg     0.7913    0.7931    0.7903      4699\n",
            "\n",
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5745    0.1875    0.2827       144\n",
            "           1     0.6959    0.4857    0.5721       245\n",
            "           2     0.4516    0.6198    0.5225       384\n",
            "           3     0.6536    0.5882    0.6192       170\n",
            "           4     0.5729    0.5652    0.5690       299\n",
            "           5     0.5465    0.6168    0.5795       381\n",
            "\n",
            "    accuracy                         0.5471      1623\n",
            "   macro avg     0.5825    0.5105    0.5242      1623\n",
            "weighted avg     0.5652    0.5471    0.5408      1623\n",
            "\n",
            "0.5829427279531956 0.7902813729312846 0.4861280544686588 0.5408034809551229\n",
            "Patience counter: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▉                                           | 1/48 [00:00<00:23,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, iter 0: loss = 0.5844382643699646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████| 48/48 [00:30<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 loss average: 0.494\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7500    0.6223    0.6802       376\n",
            "           1     0.8779    0.8848    0.8814       764\n",
            "           2     0.8294    0.8370    0.8332      1080\n",
            "           3     0.8490    0.8104    0.8292       749\n",
            "           4     0.7504    0.8385    0.7920       520\n",
            "           5     0.8335    0.8479    0.8406      1210\n",
            "\n",
            "    accuracy                         0.8263      4699\n",
            "   macro avg     0.8150    0.8068    0.8094      4699\n",
            "weighted avg     0.8264    0.8263    0.8255      4699\n",
            "\n",
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.3516    0.5347    0.4242       144\n",
            "           1     0.5795    0.6245    0.6012       245\n",
            "           2     0.5134    0.5495    0.5308       384\n",
            "           3     0.5294    0.6882    0.5985       170\n",
            "           4     0.6619    0.3077    0.4201       299\n",
            "           5     0.5718    0.5538    0.5627       381\n",
            "\n",
            "    accuracy                         0.5305      1623\n",
            "   macro avg     0.5346    0.5431    0.5229      1623\n",
            "weighted avg     0.5518    0.5305    0.5261      1623\n",
            "\n",
            "0.49435744527727365 0.8255100102150555 0.4726304893359513 0.5261467093639094\n",
            "Patience counter: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▉                                           | 1/48 [00:00<00:21,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 11, iter 0: loss = 0.2631080150604248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████| 48/48 [00:31<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 loss average: 0.431\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7239    0.7181    0.7210       376\n",
            "           1     0.9091    0.9162    0.9126       764\n",
            "           2     0.8439    0.8361    0.8400      1080\n",
            "           3     0.8383    0.8585    0.8483       749\n",
            "           4     0.8180    0.8212    0.8196       520\n",
            "           5     0.8638    0.8545    0.8592      1210\n",
            "\n",
            "    accuracy                         0.8464      4699\n",
            "   macro avg     0.8328    0.8341    0.8334      4699\n",
            "weighted avg     0.8463    0.8464    0.8463      4699\n",
            "\n",
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5244    0.2986    0.3805       144\n",
            "           1     0.5775    0.6694    0.6200       245\n",
            "           2     0.5180    0.4870    0.5020       384\n",
            "           3     0.5314    0.6471    0.5836       170\n",
            "           4     0.6175    0.5184    0.5636       299\n",
            "           5     0.5091    0.5853    0.5446       381\n",
            "\n",
            "    accuracy                         0.5434      1623\n",
            "   macro avg     0.5463    0.5343    0.5324      1623\n",
            "weighted avg     0.5452    0.5434    0.5389      1623\n",
            "\n",
            "0.43050535457829636 0.846280890528713 0.4727068757620797 0.5389342252238375\n",
            "Patience counter: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▉                                           | 1/48 [00:00<00:22,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 12, iter 0: loss = 0.4402359426021576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████| 48/48 [00:30<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 loss average: 0.376\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7939    0.7580    0.7755       376\n",
            "           1     0.9090    0.9411    0.9248       764\n",
            "           2     0.8622    0.8630    0.8626      1080\n",
            "           3     0.8745    0.8745    0.8745       749\n",
            "           4     0.8378    0.8442    0.8410       520\n",
            "           5     0.8745    0.8636    0.8690      1210\n",
            "\n",
            "    accuracy                         0.8672      4699\n",
            "   macro avg     0.8586    0.8574    0.8579      4699\n",
            "weighted avg     0.8667    0.8672    0.8669      4699\n",
            "\n",
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.3478    0.5000    0.4103       144\n",
            "           1     0.6051    0.6816    0.6411       245\n",
            "           2     0.4945    0.5833    0.5352       384\n",
            "           3     0.5738    0.6176    0.5949       170\n",
            "           4     0.6474    0.3746    0.4746       299\n",
            "           5     0.6012    0.5223    0.5590       381\n",
            "\n",
            "    accuracy                         0.5416      1623\n",
            "   macro avg     0.5450    0.5466    0.5358      1623\n",
            "weighted avg     0.5597    0.5416    0.5408      1623\n",
            "\n",
            "0.3755216511587302 0.8668891231598712 0.4761764299336812 0.5407766368756689\n",
            "Patience counter: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▉                                           | 1/48 [00:00<00:24,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13, iter 0: loss = 0.4175492823123932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████| 48/48 [00:30<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 loss average: 0.325\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8168    0.8298    0.8232       376\n",
            "           1     0.9140    0.9319    0.9229       764\n",
            "           2     0.8838    0.8870    0.8854      1080\n",
            "           3     0.8919    0.8812    0.8865       749\n",
            "           4     0.8822    0.8788    0.8805       520\n",
            "           5     0.8963    0.8860    0.8911      1210\n",
            "\n",
            "    accuracy                         0.8876      4699\n",
            "   macro avg     0.8808    0.8825    0.8816      4699\n",
            "weighted avg     0.8877    0.8876    0.8876      4699\n",
            "\n",
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5714    0.3333    0.4211       144\n",
            "           1     0.7200    0.4408    0.5468       245\n",
            "           2     0.4429    0.5859    0.5045       384\n",
            "           3     0.5833    0.6588    0.6188       170\n",
            "           4     0.6741    0.5050    0.5774       299\n",
            "           5     0.5204    0.6352    0.5721       381\n",
            "\n",
            "    accuracy                         0.5459      1623\n",
            "   macro avg     0.5854    0.5265    0.5401      1623\n",
            "weighted avg     0.5716    0.5459    0.5448      1623\n",
            "\n",
            "0.32523213714982074 0.8876240689224525 0.48804758675265053 0.5447610330568915\n",
            "Patience counter: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▉                                           | 1/48 [00:00<00:24,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 14, iter 0: loss = 0.13272742927074432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████| 48/48 [00:30<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 loss average: 0.296\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8385    0.7872    0.8121       376\n",
            "           1     0.9364    0.9254    0.9309       764\n",
            "           2     0.8938    0.8963    0.8951      1080\n",
            "           3     0.8922    0.9065    0.8993       749\n",
            "           4     0.8537    0.8981    0.8754       520\n",
            "           5     0.9042    0.8967    0.9004      1210\n",
            "\n",
            "    accuracy                         0.8942      4699\n",
            "   macro avg     0.8865    0.8850    0.8855      4699\n",
            "weighted avg     0.8943    0.8942    0.8941      4699\n",
            "\n",
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4574    0.2986    0.3613       144\n",
            "           1     0.6292    0.6163    0.6227       245\n",
            "           2     0.4440    0.6198    0.5174       384\n",
            "           3     0.5978    0.6471    0.6215       170\n",
            "           4     0.6957    0.3746    0.4870       299\n",
            "           5     0.5147    0.5512    0.5323       381\n",
            "\n",
            "    accuracy                         0.5323      1623\n",
            "   macro avg     0.5565    0.5179    0.5237      1623\n",
            "weighted avg     0.5522    0.5323    0.5282      1623\n",
            "\n",
            "0.29576147712456685 0.894120873426532 0.4833376362192382 0.5282390518009386\n",
            "Patience counter: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▉                                           | 1/48 [00:00<00:23,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 15, iter 0: loss = 0.11548823863267899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████| 48/48 [00:31<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 loss average: 0.263\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8622    0.8484    0.8552       376\n",
            "           1     0.9450    0.9450    0.9450       764\n",
            "           2     0.9038    0.9222    0.9129      1080\n",
            "           3     0.9039    0.9039    0.9039       749\n",
            "           4     0.9180    0.9038    0.9109       520\n",
            "           5     0.9185    0.9124    0.9154      1210\n",
            "\n",
            "    accuracy                         0.9125      4699\n",
            "   macro avg     0.9086    0.9060    0.9072      4699\n",
            "weighted avg     0.9125    0.9125    0.9125      4699\n",
            "\n",
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4309    0.3681    0.3970       144\n",
            "           1     0.6031    0.6327    0.6175       245\n",
            "           2     0.4578    0.6354    0.5322       384\n",
            "           3     0.5385    0.6176    0.5753       170\n",
            "           4     0.6493    0.4582    0.5373       299\n",
            "           5     0.5757    0.4593    0.5109       381\n",
            "\n",
            "    accuracy                         0.5354      1623\n",
            "   macro avg     0.5425    0.5285    0.5284      1623\n",
            "weighted avg     0.5487    0.5354    0.5335      1623\n",
            "\n",
            "0.26334949031782645 0.9124981108508285 0.4806710801115359 0.5335401440648773\n",
            "Patience counter: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|                                                    | 0/48 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 16, iter 0: loss = 0.181615948677063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████| 48/48 [00:30<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 loss average: 0.241\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8636    0.8590    0.8613       376\n",
            "           1     0.9485    0.9634    0.9558       764\n",
            "           2     0.9129    0.9028    0.9078      1080\n",
            "           3     0.9022    0.9119    0.9070       749\n",
            "           4     0.9112    0.9077    0.9094       520\n",
            "           5     0.9187    0.9157    0.9172      1210\n",
            "\n",
            "    accuracy                         0.9144      4699\n",
            "   macro avg     0.9095    0.9101    0.9098      4699\n",
            "weighted avg     0.9144    0.9144    0.9144      4699\n",
            "\n",
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4080    0.3542    0.3792       144\n",
            "           1     0.6455    0.5796    0.6108       245\n",
            "           2     0.4520    0.5521    0.4971       384\n",
            "           3     0.5638    0.6235    0.5922       170\n",
            "           4     0.5923    0.5686    0.5802       299\n",
            "           5     0.5479    0.4803    0.5119       381\n",
            "\n",
            "    accuracy                         0.5323      1623\n",
            "   macro avg     0.5349    0.5264    0.5285      1623\n",
            "weighted avg     0.5374    0.5323    0.5325      1623\n",
            "\n",
            "0.2412242383385698 0.9143836816431876 0.4866941540043262 0.5325275353175192\n",
            "Patience counter: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▉                                           | 1/48 [00:00<00:21,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 17, iter 0: loss = 0.3484552204608917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████| 48/48 [00:30<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 loss average: 0.208\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9122    0.8564    0.8834       376\n",
            "           1     0.9506    0.9581    0.9544       764\n",
            "           2     0.9114    0.9241    0.9177      1080\n",
            "           3     0.9158    0.9146    0.9152       749\n",
            "           4     0.9216    0.9269    0.9243       520\n",
            "           5     0.9215    0.9215    0.9215      1210\n",
            "\n",
            "    accuracy                         0.9223      4699\n",
            "   macro avg     0.9222    0.9169    0.9194      4699\n",
            "weighted avg     0.9223    0.9223    0.9222      4699\n",
            "\n",
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4700    0.3264    0.3852       144\n",
            "           1     0.6038    0.6531    0.6275       245\n",
            "           2     0.4568    0.5781    0.5103       384\n",
            "           3     0.5843    0.6118    0.5977       170\n",
            "           4     0.6907    0.4482    0.5436       299\n",
            "           5     0.5425    0.5696    0.5557       381\n",
            "\n",
            "    accuracy                         0.5447      1623\n",
            "   macro avg     0.5580    0.5312    0.5367      1623\n",
            "weighted avg     0.5567    0.5447    0.5428      1623\n",
            "\n",
            "0.20750747923739254 0.9222141853307801 0.4595713379998748 0.5428483879597652\n",
            "Patience counter: 11\n",
            "Done! It took 7.1e+02 secs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "2aDr-qwpQgDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_loss, w_valid_f1, valid_predictions = solver.evaluate(eval_data_loader, mode=\"valid\")\n"
      ],
      "metadata": {
        "id": "i_nNRV1eF84G"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [e[1] for e in eval_data_loader]\n",
        "Labels = [label for utt in labels for label in utt]\n",
        "Labels = [e for k in Labels for e in k]"
      ],
      "metadata": {
        "id": "uASIxVQNKTUk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solver.print_metric(Labels, valid_predictions, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTsuynDAI7ol",
        "outputId": "a67ed45a-d9bf-4717-bdb6-b35b5a3af0cf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4571    0.2500    0.3232       128\n",
            "           1     0.3358    0.6133    0.4340        75\n",
            "           2     0.3833    0.4508    0.4143       244\n",
            "           3     0.6194    0.4511    0.5220       184\n",
            "           4     0.5455    0.4324    0.4824       222\n",
            "           5     0.4723    0.5620    0.5133       258\n",
            "\n",
            "    accuracy                         0.4608      1111\n",
            "   macro avg     0.4689    0.4599    0.4482      1111\n",
            "weighted avg     0.4808    0.4608    0.4596      1111\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4595713379998748"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "4SrZohA7Qq4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmaK61ZaZmvC",
        "outputId": "b30138ca-cdb0-404f-abf7-dfc2d09c255a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/conv-emotion/TL-ERC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "_, videoSpeakers, videoLabels, _, _, _, videoSentence, trainVid, testVid = pickle.load(open(\"/content/drive/MyDrive/Depot_Mouhamed-20220228T100527Z-001/DialogueRNN/DialogueRNN/IEMOCAP_features/IEMOCAP_features_raw.pkl\", 'rb'), encoding='latin1')\n",
        "\n"
      ],
      "metadata": {
        "id": "-4bzeCp_SRBM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from iemocap_preprocess import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ryt3HHRTZ6T4",
        "outputId": "92532362-0b81-4a14-d6a7-f69dcef2cd12"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading SpaCy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv = videoSentence['Ses01F_impro01']\n",
        "conv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kidSRfGraLLF",
        "outputId": "8b22c895-d3cf-4d8e-e5a4-e214e378fd81"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Excuse me.',\n",
              " 'Do you have your forms?',\n",
              " 'Yeah.',\n",
              " 'Let me see them.',\n",
              " 'Is there a problem?',\n",
              " 'Who told you to get in this line?',\n",
              " \"Okay. But I didn't tell you to get in this line if you are filling out this particular form.\",\n",
              " \"Well what's the problem?  Let me change it.\",\n",
              " 'This form is a Z.X.four.',\n",
              " \"You can't--  This is not the line for Z.X.four.  If you're going to fill out the Z.X.four, you need to have a different form of ID.\",\n",
              " \"What?  I'm getting an ID.  This is why I'm here.  My wallet was stolen.\",\n",
              " 'No. I need another set of ID to prove this is actually you.',\n",
              " 'How am I supposed to get an ID without an ID?  How does a person get an ID in the first place?',\n",
              " \"I don't know.  But I need an ID to pass this form along.  I can't just send it along without an ID.\",\n",
              " \"I'm here to get an ID.\",\n",
              " 'No.  I need another ID, a separate one.',\n",
              " 'Like what?  Like a birth certificate?',\n",
              " \"A birth certificate, a passport...a student ID; didn't you go to school?  Anything?\",\n",
              " \"Yes but my wallet was stolen, I don't have anything.  I don't have any credit cards, I don't have my ID.  Don't you have things on file here?\",\n",
              " 'Yeah.  We keep it on file, but we need an ID to access that file.',\n",
              " \"That's out of control.\",\n",
              " \"I don't understand why this is so complicated for people when they get here.  It's just a simple form.  I just need an ID.\",\n",
              " 'How long have you been working here?',\n",
              " 'Clearly.  You know, do you have like a supervisor or something?',\n",
              " \"Yeah.  Do you want to see my supervisor?  Huh? Yeah.  Do you want to see my supervisor?  Fine.  I'll be right back.\",\n",
              " 'That would - I would appreciate that.  Yeah.']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(conv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smUpu77n9300",
        "outputId": "a66b581b-f7c7-4565-8fa8-c1f46657e98e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = videoLabels['Ses01F_impro01']\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9JROCX-aiui",
        "outputId": "ba1536e4-9c98-469d-b1dd-51dd98cfd026"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 5, 2, 5, 2, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 5, 2, 3, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB1gRut098ja",
        "outputId": "eb43fb85-f35d-45b5-d37d-6c7e47c478cb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "26 répliques alors"
      ],
      "metadata": {
        "id": "otk6O5KN-AWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "    \n",
        "# Load the dataset\n",
        "iemocap = IEMOCAP()\n",
        "iemocap.load_iemocap_data()\n",
        "\n",
        "# Maximum valid length of sentence\n",
        "# => SOS/EOS will surround sentence (EOS for source / SOS for target)\n",
        "# => maximum length of tensor = max_sentence_length + 1\n",
        "parser.add_argument('-s', '--max_sentence_length', type=int, default=30)\n",
        "\n",
        "# Vocabulary\n",
        "parser.add_argument('--max_vocab_size', type=int, default=20000)\n",
        "parser.add_argument('--min_vocab_frequency', type=int, default=5)\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "max_sent_len = args.max_sentence_length\n",
        "max_conv_len = iemocap.max_conv_length\n",
        "max_vocab_size = args.max_vocab_size\n",
        "min_freq = args.min_vocab_frequency\n",
        "\n",
        "\n",
        "conv_sentences = list([tokenize_conversation(conv)])\n",
        "conversation_length = [min(len(conv), max_conv_len)]\n",
        "\n",
        "conv_labels = [labels]\n",
        "# fix labels as per conversation_length\n",
        "for idx, conv_len in enumerate(conversation_length):\n",
        "    conv_labels[idx]=conv_labels[idx][:conv_len]\n",
        "\n",
        "\n",
        "sentences, sentence_length = pad_sentences(\n",
        "    conv_sentences,\n",
        "    max_sentence_length=max_sent_len,\n",
        "    max_conversation_length=max_conv_len)\n",
        "\n",
        "for sentence_len, label in zip(conversation_length, conv_labels):\n",
        "    assert(sentence_len ==len(label))\n"
      ],
      "metadata": {
        "id": "XklCkYTkZcHJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentences[0])"
      ],
      "metadata": {
        "id": "TmbwTbZWbyhj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57cac99b-0198-4299-eb1d-952d20144d00"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sentences[0] est le premier dialoque qui contient 26 répliques, tokenizés"
      ],
      "metadata": {
        "id": "UVgNLHKC-UKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "infer_loader = get_loader(\n",
        "    sentences,\n",
        "    [[0 for s in conv] for conv in sentences ],\n",
        "    conversation_length=conversation_length,\n",
        "    sentence_length=sentence_length,\n",
        "    batch_size=val_config.eval_batch_size,\n",
        "    shuffle=False)"
      ],
      "metadata": {
        "id": "N1IrMHxsXn0w"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infer_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9gj-Jood9GN",
        "outputId": "cf28672c-171f-4b14-b071-7275c48ea4b1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fdd18bd4650>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(conversations, labels, conversation_length, sentence_length, type_ids, masks):\n",
        "  # conversations: (batch_size) list of conversations\n",
        "  #   conversation: list of sentences\n",
        "  #   sentence: list of tokens\n",
        "  # conversation_length: list of int\n",
        "  # sentence_length: (batch_size) list of conversation list of sentence_lengths\n",
        "\n",
        "  input_conversations = conversations\n",
        "\n",
        "  # flatten input and target conversations\n",
        "  input_sentences = [sent for conv in input_conversations for sent in conv]\n",
        "  input_labels = [label for conv in labels for label in conv]\n",
        "  input_sentence_length = [l for len_list in sentence_length for l in len_list]\n",
        "  input_conversation_length = [l for l in conversation_length]\n",
        "  input_masks = [mask for conv in masks for mask in conv]\n",
        "  orig_input_labels = input_labels\n",
        "\n",
        "  with torch.no_grad():\n",
        "      # transfering the input to cuda\n",
        "      input_sentences = to_var(torch.LongTensor(input_sentences))\n",
        "      input_labels = to_var(torch.LongTensor(input_labels))\n",
        "      input_sentence_length = to_var(torch.LongTensor(input_sentence_length))\n",
        "      input_conversation_length = to_var(torch.LongTensor(input_conversation_length))\n",
        "      input_masks = to_var(torch.LongTensor(input_masks))\n",
        "\n",
        "  sentence_logits = solver.model(\n",
        "      input_sentences,\n",
        "      input_sentence_length,\n",
        "      input_conversation_length,\n",
        "      input_masks)\n",
        "\n",
        "  present_predictions = list(np.argmax(sentence_logits.detach().cpu().numpy(), axis=1))\n",
        "  print(present_predictions)"
      ],
      "metadata": {
        "id": "9WQRygc9QxL6"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference(*next(iter(infer_loader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jas_48S4R5tk",
        "outputId": "030c241d-eb14-4773-bb5f-2589c0c2dcaa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 5, 2, 5, 2, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 5, 2, 3, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from util import to_var"
      ],
      "metadata": {
        "id": "BT1gNyH7Rcb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = next(iter(eval_data_loader))\n",
        "print(np.array(input[2],dtype=object ).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpGQAsTVSbOo",
        "outputId": "00a515bc-57f4-46c0-e6de-7137d0ad1fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences=load_pickle(val_config.sentences_path)"
      ],
      "metadata": {
        "id": "rdWO7Gc5T2bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l2i = {'neutral': 0, 'surprise': 1, 'fear': 2, 'sadness': 3, 'joy': 4, 'disgust': 5, 'anger':6}\n",
        "i2l = {v:k for k,v in l2i.items()}"
      ],
      "metadata": {
        "id": "vUd2a4fVWKFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_id = 1\n",
        "for replique,label in zip(sentences[conv_id],input[1][conv_id]):\n",
        "\n",
        "  print(\" \".join(replique))\n",
        "  print(i2l[label]) \n"
      ],
      "metadata": {
        "id": "77g6CgCHTc9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels, sentences\n",
        "labels=load_pickle(val_config.label_path)\n",
        "sentences=load_pickle(val_config.sentences_path)"
      ],
      "metadata": {
        "id": "5CCyw68jWqIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [[3,\n",
        " 2,\n",
        " 2,\n",
        " 3]]"
      ],
      "metadata": {
        "id": "c7W3A1VFXa6v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}